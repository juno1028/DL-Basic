{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy 배열로도 입력을 받고 싶으면,\n",
    "def step_function(x):\n",
    "    y = x > 0\n",
    "    return y.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Numpy에서 활용되는 트릭\n",
    "import numpy as np\n",
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "y = x > 0\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fc63beb3acb9>:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = y.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "y = y.astype(np.int)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-1d3a93afdd61>:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return np.array(x > 0, dtype = np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARbUlEQVR4nO3df4wc513H8c/Hexf6MyTgo6Q+G1vIpbUggXK4kSqUQGhrp6EWEn8kgQZCK8tSjFKJihgq6B/9C0VAVMWtsSIrFAoWUgM1lYtJJSB/VEF2QpLWCQ6HS+OLA7nQqkVJhW9mvvyxe5flPDO7tnd37pl7vyQrNzvjve8qz370+LvPM+uIEAAgfRuaLgAAMBoEOgC0BIEOAC1BoANASxDoANASU0394o0bN8bWrVub+vUAkKQnnnjilYiYKTvXWKBv3bpVp06daurXA0CSbH+z6hwtFwBoCQIdAFqCQAeAliDQAaAlCHQAaAkCHQBagkAHgJYg0AGgJQh0AGgJAh0AWoJAB4CWINABoCUIdABoiYGBbvuI7Zdtf73ivG1/2va87Wdsv3v0ZQIABhlmhv6wpF0153dL2t77s1fSZ6+8LADApRp4P/SIeMz21ppL9kj6XESEpMdtX2P7uoh4aUQ1Ao363oVcT77wbRURTZeClpi99k3atvHNI3/eUXzBxSZJ5/qOF3qPXRTotveqO4vXli1bRvCrgfH7k8f+XQ985d+aLgMtsu+mH9WB3e8c+fOOItBd8ljpVCYiDks6LElzc3NMd5CE734v0xunO/qzj+xsuhS0xNuufsNYnncUgb4gaXPf8ayk8yN4XmBNyItC3ze9QXNbf6DpUoBao1i2eEzSXb3VLjdK+g79c7TJUhGa2lD2D1FgbRk4Q7f9l5JulrTR9oKkT0qalqSIOCTpuKRbJc1Lek3S3eMqFmhCnoemNrBlA2vfMKtc7hhwPiTdM7KKgDVmqSjUYYaOBDDtAAbIi9BUh0DH2kegAwNk9NCRCAIdGCDLC3roSAKjFBggL4IeOpJAoAMDZEVomh46EkCgAwNkOTN0pIFABwbICnroSAOjFBiAZYtIBYEODLBEywWJINCBAXLWoSMRBDowQFaEpjq8VbD2MUqBAbobi5ihY+0j0IEB2FiEVBDowADdjUW8VbD2MUqBAbKc2+ciDQQ6MAB3W0QqCHRgADYWIRUEOjDAErfPRSIYpcAArHJBKgh0YICMlgsSQaADA/ChKFJBoAM1IqLXcuGtgrWPUQrUyIuQJE0zQ0cCCHSgRtYL9A49dCSAQAdqLAc6PXSkgEAHauT5cqDzVsHaxygFaiwVhSSxbBFJINCBGnnBDB3pGGqU2t5l+4ztedsHSs5/v+2/tf207dO27x59qcDkLeW9GTo9dCRgYKDb7kg6KGm3pB2S7rC9Y9Vl90h6NiJukHSzpD+0fdWIawUmbnmGztZ/pGCYGfpOSfMRcTYiLkg6KmnPqmtC0lttW9JbJH1LUjbSSoEGrKxyoYeOBAwT6Jsknes7Xug91u9BSe+SdF7S1yTdGxHF6ieyvdf2KdunFhcXL7NkYHIyVrkgIcOM0rKpSaw6/oCkpyS9XdJPSnrQ9tUX/aWIwxExFxFzMzMzl1wsMGlZb5ULLRekYJhAX5C0ue94Vt2ZeL+7JT0SXfOSviHpnaMpEWjOytZ/Wi5IwDCBflLSdtvbeh903i7p2KprXpB0iyTZfpukH5N0dpSFAk1YyvlQFOmYGnRBRGS290s6Iakj6UhEnLa9r3f+kKRPSXrY9tfUbdHcFxGvjLFuYCJYh46UDAx0SYqI45KOr3rsUN/P5yW9f7SlAc3L2CmKhDDtAGq8vsqFQMfaR6ADNdhYhJQQ6ECNbGWVC28VrH2MUqBGlrMOHekg0IEafMEFUkKgAzVWli3SckECGKVADW6fi5QQ6EANVrkgJQQ6UIPb5yIlBDpQI1tpufBWwdrHKAVqZLRckBACHajB7XOREgIdqMEMHSkh0IEafAUdUsIoBWrkRSGbGTrSQKADNZaKYFMRkkGgAzXyIpidIxkEOlAjy0PT9M+RCEYqUCMrCnVYsohEEOhAjawIVrggGYxUoEaWF3woimQQ6ECNjA9FkRACHaiRF8G2fySDQAdqZDkzdKSDQAdqZEXBh6JIBiMVqJEXwZdbIBkEOlBjKWfrP9IxVKDb3mX7jO152wcqrrnZ9lO2T9v+p9GWCTSDrf9IydSgC2x3JB2U9D5JC5JO2j4WEc/2XXONpM9I2hURL9j+oXEVDExSVhSa6vAPWaRhmJG6U9J8RJyNiAuSjkras+qaOyU9EhEvSFJEvDzaMoFmZLRckJBhAn2TpHN9xwu9x/q9Q9K1tv/R9hO27yp7Itt7bZ+yfWpxcfHyKgYmiI1FSMkwgV42mmPV8ZSkn5b0QUkfkPR7tt9x0V+KOBwRcxExNzMzc8nFApPW3VhEywVpGNhDV3dGvrnveFbS+ZJrXomIVyW9avsxSTdIen4kVQINWcoLZuhIxjBTj5OSttveZvsqSbdLOrbqmi9K+lnbU7bfJOk9kp4bbanA5OV8YxESMnCGHhGZ7f2STkjqSDoSEadt7+udPxQRz9n+O0nPSCokPRQRXx9n4cAkdDcW0XJBGoZpuSgijks6vuqxQ6uO75d0/+hKA5q3VHD7XKSDqQdQI+fmXEgIgQ7UyLh9LhJCoAM1WIeOlBDoQI3uV9DxNkEaGKlADZYtIiUEOlBjqQh16KEjEQQ6UIMZOlJCoAMVIqIX6LxNkAZGKlAhK7r3oGOGjlQQ6ECFvBfo9NCRCgIdqLA8Q5+m5YJEMFKBClleSBIbi5AMAh2osNJDp+WCRBDoQIV85UNR3iZIAyMVqLDUa7mwygWpINCBCjktFySGQAcqLOW9ZYvM0JEIAh2oQA8dqWGkAhWyotdDp+WCRBDoQIUsZ+s/0kKgAxWW16HTQ0cqCHSgwnIPfbrD2wRpYKQCFdj6j9QQ6EAFbp+L1BDoQIXXNxbxNkEaGKlABbb+IzUEOlAhZ5ULEjNUoNveZfuM7XnbB2qu+xnbue1fHl2JQDNWvuCCjUVIxMBAt92RdFDSbkk7JN1he0fFdX8g6cSoiwSasLxTtMPWfyRimJG6U9J8RJyNiAuSjkraU3Ldb0r6gqSXR1gf0Bh2iiI1wwT6Jknn+o4Xeo+tsL1J0i9JOlT3RLb32j5l+9Ti4uKl1gpMFLfPRWqGCfSy0Ryrjh+QdF9E5HVPFBGHI2IuIuZmZmaGrRFoxBIfiiIxU0NcsyBpc9/xrKTzq66Zk3TUtiRtlHSr7Swi/mYkVQINyFeWLdJDRxqGCfSTkrbb3ibpRUm3S7qz/4KI2Lb8s+2HJX2JMEfq+JJopGZgoEdEZnu/uqtXOpKORMRp2/t652v75kCq2PqP1AwzQ1dEHJd0fNVjpUEeEb9+5WUBzWNjEVJDcxCosLxscZoeOhLBSAUqZEUhW9rADB2JINCBClkR9M+RFAIdqJAXwZJFJIXRClRYygtm6EgKgQ5UyItQhzXoSAiBDlTIaLkgMYxWoEJGywWJIdCBClkRbPtHUgh0oEKWs2wRaSHQgQp5EWz7R1IIdKBCVhSa7vAWQToYrUCFLGeGjrQQ6EAFtv4jNQQ6UCEvQlO0XJAQRitQYSkvaLkgKQQ6UCGn5YLEEOhAhYyWCxLDaAUqZAVb/5EWAh2owLJFpIZAByrkRWiae7kgIQQ6UCErQh1un4uEMFqBCvTQkRoCHaiQc7dFJIZAByoscT90JIZABypw+1ykhkAHKnS/go63CNIx1Gi1vcv2Gdvztg+UnP8V28/0/nzV9g2jLxWYLO62iNQMDHTbHUkHJe2WtEPSHbZ3rLrsG5JuiojrJX1K0uFRFwpMWlaEOvTQkZBhZug7Jc1HxNmIuCDpqKQ9/RdExFcj4tu9w8clzY62TGDy8iI0TcsFCRlmtG6SdK7veKH3WJWPSPpy2Qnbe22fsn1qcXFx+CqBCYsIPhRFcoYJ9LIRHaUX2j+nbqDfV3Y+Ig5HxFxEzM3MzAxfJTBhWdEd4vTQkZKpIa5ZkLS573hW0vnVF9m+XtJDknZHxH+PpjygGflyoHP7XCRkmNF6UtJ229tsXyXpdknH+i+wvUXSI5I+HBHPj75MYLKW8kISM3SkZeAMPSIy2/slnZDUkXQkIk7b3tc7f0jS70v6QUmfsS1JWUTMja9sYLyWZ+j00JGSYVouiojjko6veuxQ388flfTR0ZYGNGe5h87tc5ESGoRAiSxfnqHzFkE6GK1Aiazo9dCZoSMhBDpQYnmGzoeiSAmBDpTI+FAUCSLQgRL5yoeivEWQDkYrUGJ5HTozdKSEQAdK5Gz9R4IIdKBExtZ/JIjRCpTI2PqPBBHoQAm2/iNFBDpQgq3/SBGBDpRY3inK1n+khNEKlGCnKFJEoAMlXv+CCwId6SDQgRJLrENHggh0oERODx0JYrQCJeihI0UEOlAio4eOBBHoQAlun4sUEehAiby39X+aHjoSwmgFSqzM0Gm5ICEEOlAiY9kiEkSgAyVevx86bxGkg9EKlFji9rlIEIEOlMiLkC1tINCREAIdKJEVwQoXJIcRC5TI8oI16EgOgQ6UyIqgf47kDBXotnfZPmN73vaBkvO2/ene+Wdsv3v0pQKTkxfBtn8kZ2rQBbY7kg5Kep+kBUknbR+LiGf7LtstaXvvz3skfbb335G7kBV67UI2jqcGVrz6vzl3WkRyBga6pJ2S5iPirCTZPippj6T+QN8j6XMREZIet32N7esi4qVRF/zos/+le/7iyVE/LXCR2Wvf2HQJwCUZJtA3STrXd7ygi2ffZddskvT/At32Xkl7JWnLli2XWqskacfbr9Ynf3HHZf1d4FLsuO7qpksALskwgV7WSIzLuEYRcVjSYUmam5u76Pwwtm18s7Zt3HY5fxUAWm2YJuGCpM19x7OSzl/GNQCAMRom0E9K2m57m+2rJN0u6diqa45Juqu32uVGSd8ZR/8cAFBtYMslIjLb+yWdkNSRdCQiTtve1zt/SNJxSbdKmpf0mqS7x1cyAKDMMD10RcRxdUO7/7FDfT+HpHtGWxoA4FKw0BYAWoJAB4CWINABoCUIdABoCQIdAFqCQAeAliDQAaAlCHQAaAkCHQBagkAHgJYg0AGgJQh0AGgJd++r1cAvthclfbORX35lNkp6pekiGrAeX/d6fM3S+nzdKb3mH4mImbITjQV6qmyfioi5puuYtPX4utfja5bW5+tuy2um5QIALUGgA0BLEOiX7nDTBTRkPb7u9fiapfX5ulvxmumhA0BLMEMHgJYg0AGgJQj0K2D747bD9samaxk32/fb/lfbz9j+a9vXNF3TONneZfuM7XnbB5quZ9xsb7b9D7afs33a9r1N1zQptju2/8X2l5qu5UoR6JfJ9mZJ75P0QtO1TMijkn48Iq6X9Lyk32m4nrGx3ZF0UNJuSTsk3WF7R7NVjV0m6bci4l2SbpR0zzp4zcvulfRc00WMAoF++f5Y0m9LWhefKkfE30dE1jt8XNJsk/WM2U5J8xFxNiIuSDoqaU/DNY1VRLwUEU/2fv4fdQNuU7NVjZ/tWUkflPRQ07WMAoF+GWx/SNKLEfF007U05DckfbnpIsZok6RzfccLWgfhtsz2Vkk/Jemfm61kIh5Qd2JWNF3IKEw1XcBaZfsrkn645NQnJP2upPdPtqLxq3vNEfHF3jWfUPef55+fZG0T5pLH1sW/xGy/RdIXJH0sIr7bdD3jZPs2SS9HxBO2b266nlEg0CtExC+UPW77JyRtk/S0banbenjS9s6I+M8JljhyVa95me1fk3SbpFui3RsYFiRt7juelXS+oVomxva0umH++Yh4pOl6JuC9kj5k+1ZJb5B0te0/j4hfbbiuy8bGoitk+z8kzUVEKndquyy2d0n6I0k3RcRi0/WMk+0pdT/4vUXSi5JOSrozIk43WtgYuTs7+VNJ34qIjzVdz6T1Zugfj4jbmq7lStBDx7AelPRWSY/afsr2oaYLGpfeh7/7JZ1Q98PBv2pzmPe8V9KHJf187//vU72ZKxLCDB0AWoIZOgC0BIEOAC1BoANASxDoANASBDoAtASBDgAtQaADQEv8H3KLPY8+S91KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def step_function(x):\n",
    "    return np.array(x > 0, dtype = np.int)\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = step_function(x)\n",
    "plt.plot(x,y)\n",
    "plt.ylim(-0.1, 1.1) # y축의 범위 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.4 시그모이드 함수 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26894142, 0.73105858, 0.88079708])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 4.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy의 브로드캐스트\n",
    "t = np.array([1.0, 2.0, 3.0])\n",
    "1.0 + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.5       , 0.33333333])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 / t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1) # y축 범위 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.7 ReLU 함수(Rectified Linear Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.1 다차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([1,2,3,4])\n",
    "print(A)\n",
    "print(np.ndim(A))\n",
    "A.shape\n",
    "A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[1,2],[3,4],[5,6]])\n",
    "print(B)\n",
    "print(np.ndim(B))\n",
    "B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.2 행렬의 곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,2],[3,4]])\n",
    "B = np.array([[5,6],[7,8]])\n",
    "np.dot(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.3 신경망에서의 행렬 곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([1,2])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 5]\n",
      " [2 4 6]]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[1,3,5], [2,4,6]])\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 11 17]\n"
     ]
    }
   ],
   "source": [
    "Y = np.dot(X, W)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2,)\n",
      "(3,)\n",
      "[0.3 0.7 1.1]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1.0, 0.5])\n",
    "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "B1 = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "print(W1.shape)\n",
    "print(X.shape)\n",
    "print(B1.shape)\n",
    "\n",
    "A1 = np.dot(X, W1) + B1\n",
    "print(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7 1.1]\n",
      "[0.57444252 0.66818777 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "Z1 = sigmoid(A1)\n",
    "\n",
    "print(A1)\n",
    "print(Z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 2)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "# 1층에서 2층으로 넘어가는 과정\n",
    "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "B2 = np.array([0.1, 0.2])\n",
    "\n",
    "print(Z1.shape) # (3, )\n",
    "print(W2.shape) # (3, 2)\n",
    "print(B2.shape) # (2, )\n",
    "\n",
    "A2 = np.dot(Z1, W2) + B2\n",
    "Z2 = sigmoid(A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "# 2층에서 출력층으로의 전달\n",
    "# 출력층의 구현도 그동안의 구현과 거의 같다. 딱 하나, 활성화 함수만 지금까지의 은닉층과 다르다.\n",
    "def identify_function(x):\n",
    "    return x\n",
    "\n",
    "W3 = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "B3 = np.array([0.1, 0.2])\n",
    "\n",
    "A3 = np.dot(Z2, W3) + B3\n",
    "Y = identify_function(A3) # 혹은 Y = A3\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.3 구현 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
    "    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "    network['b2'] = np.array([0.1, 0.2])\n",
    "    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "    network['b3'] = np.array([0.1, 0.2])\n",
    "    \n",
    "    return network\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = identify_function(a3)\n",
    "    \n",
    "    return y\n",
    "\n",
    "network = init_network()\n",
    "x = np.array([1.0, 0.5])\n",
    "y = forward(network, x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.1 항등 함수와 소프트맥스 함수 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.3, 2.9, 4.0])\n",
    "\n",
    "exp_a = np.exp(a) # 지수 함수\n",
    "print(exp_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.1221542101633\n"
     ]
    }
   ],
   "source": [
    "sum_exp_a = np.sum(exp_a)\n",
    "print(sum_exp_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "y = exp_a / sum_exp_a\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.2 소프트맥스 함수 구현 시 주의점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-df8cc25774d8>:3: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(a) / np.sum(np.exp(a)) # 소프트맥스 함수의 계산 -> 제대로 계산되지 않는다.\n",
      "<ipython-input-27-df8cc25774d8>:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.exp(a) / np.sum(np.exp(a)) # 소프트맥스 함수의 계산 -> 제대로 계산되지 않는다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오버플로 문제를 해결하기 위해 C라는 임의의 정수를 분자와 분모 양쪽에 곱한다.\n",
    "a = np.array([1010, 1000, 990])\n",
    "np.exp(a) / np.sum(np.exp(a)) # 소프트맥스 함수의 계산 -> 제대로 계산되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.max(a) # c = 1010 (최댓값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, -10, -20])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a - c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(a - c) / np.sum(np.exp(a - c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위를 바탕으로 소프트맥스 함수 다시 구현\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a-c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.3 소프트맥스 함수의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": 소프트맥스 함수 출력의 총합은 1이다.(`중요`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.3, 2.9, 4.0])\n",
    "y = softmax(a)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": 이 성질 덕분에 소프트맥스 함수의 출력을 '확률'로 해석할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 22.02.10 목"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 손글씨 숫자 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "# 처음 한 번은 몇 분 정도 걸립니다.\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "# rkr xpdlxjdml gudtkd cnffur\n",
    "print(x_train.shape) # (60000, 784)\n",
    "print(t_train.shape) # (60000,)\n",
    "print(x_test.shape) # (10000, 784)\n",
    "print(t_test.shape) # (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from PIL import Image\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()\n",
    "    \n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label) # 5\n",
    "\n",
    "print(img.shape) #(784,)\n",
    "img = img.reshape(28, 28) # 원래 이미지의 모양으로 변형\n",
    "print(img.shape) # (28, 28)\n",
    "\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.2 신경망의 추론 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label = False)\n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", \"rb\") as f:\n",
    "        network = pickle.load(f)\n",
    "        \n",
    "    return network\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'],network['W2'],network['W3']\n",
    "    b1, b2, b3 = network['b1'],network['b2'],network['b3']\n",
    "    \n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "        \n",
    "print(\"Accuracy: \" + str(float(accuracy_cnt)/len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.3 배치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = init_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50, 100)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "print(W1.shape)\n",
    "print(W2.shape)\n",
    "print(W3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # 배치 크기\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "    \n",
    "print(\"Accuracy: \" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0.1, 0.8, 0.1], [0.3, 0.1, 0.6], [0.2, 0.5, 0.3],[0.8, 0.1, 0.1]])\n",
    "y = np.argmax(x, axis=1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([1,2,1,0])\n",
    "t = np.array([1,2,0,0])\n",
    "print(y == t)\n",
    "np.sum(y == t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1 평균 제곱 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답은 '2'\n",
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "# 예1 : '2'일 확률이 가장 높다고 추정함 (0.6)\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예2 : '7'일 확률이 가장 높다고 추정함 (0.6)\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답은 '2'\n",
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "# 예1 : '2'일 확률이 가장 높다고 추정함 (0.6)\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예2 : '7'일 확률이 가장 높다고 추정함 (0.6)\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.3 미니배치 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape) # (60000, 784)\n",
    "print(t_train.shape) # (60000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47155, 37819, 32938, 38019, 27775, 50922, 40318, 57052, 10048,\n",
       "       51734])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(60000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y가 1차원이라면, 즉 데이터 하나당 교차 엔트로피 오차를 구하는 경우는 reshape 함수로 데이터의 형상을 바꿔준다.\n",
    "# 레이블이 원-핫 인코딩일 때,\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batchsize = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7) / batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 수치 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나쁜 구현 예\n",
    "def numerical_diff(f, x):\n",
    "    h = 10e-50 # 반올림 오차 발생\n",
    "    return (f(x + h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중앙 차분 활용\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.3 편미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "    # 또는 return np.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_tmp1(x0):\n",
    "    return x0*x0 + 4.0**2.0\n",
    "\n",
    "numerical_diff(function_tmp1, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 기울기(Gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x) # x와 형상이 같은 배열을 생성\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        # f(x+h) 계산\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # f(x-h) 계산\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([0.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 0.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x = init_x, lr=0.1, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.58983747e+13, -1.29524862e+12])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률이 너무 큰 예 : lr=10.0\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x = init_x, lr=10.0, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.99999994,  3.99999992])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률이 너무 작은 예 : lr=1e-10\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x = init_x, lr=1e-10, step_num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.2 신경망에서의 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2, 3) # 정규분포로 초기화\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = simpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.85136955  1.25719611 -1.46256473]\n",
      " [-1.49849733 -0.43719451  0.52281333]]\n"
     ]
    }
   ],
   "source": [
    "print(net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.85946933  0.3608426  -0.40700684]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p) # 최댓값의 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([0,0,1]) # 정답 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.220570279045225"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04142551  0.38153738 -0.42296289]\n",
      " [ 0.06213827  0.57230607 -0.63444433]]\n"
     ]
    }
   ],
   "source": [
    "def f(W):\n",
    "    return net.loss(x, t)\n",
    "\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda w: net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.1 2층 신경망 클래스 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "net.params['W1'].shape # (784, 100)\n",
    "net.params['b1'].shape # (100, )\n",
    "net.params['W2'].shape # (100, 10)\n",
    "net.params['b2'].shape # (10, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(100, 784) # 더미 입력 데이터(100장 분량)\n",
    "t = np.random.rand(100, 10) # 더미 정답 레이블(100장 분량)\n",
    "\n",
    "grads = net.numerical_gradient(x, t) # 기울기 계산\n",
    "\n",
    "grads['W1'].shape # (784, 100)\n",
    "grads['b1'].shape # (100, )\n",
    "grads['W2'].shape # (100, 10)\n",
    "grads['b2'].shape # (10, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.2 미니배치 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size/batch_size,1)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000 # 반복 횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100 # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_batch, t_batch) # 성능 개선판!\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "if i % iter_per_epoch == 0:\n",
    "    train_acc = network.accuracy(x_train, t_train)\n",
    "    test_acc = network.accuracy(x_test, t_test)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_acc_list.append(test_acc)\n",
    "    print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 계산 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.1 계산 그래프로 풀다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x * y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y # x와 y를 바꾼다.\n",
    "        dy = dout * self.x\n",
    "        \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "print(price) # 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2 110.00000000000001 200\n"
     ]
    }
   ],
   "source": [
    "# 역전파\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(dapple, dapple_num, dtax) # 2.2 110 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "110.00000000000001 2.2 165.0 3.3000000000000003 650\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들 \n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tx_layer = MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num) #(1)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num) #(2)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price) #(3)\n",
    "price = mul_tax_layer.forward(all_price, tax) #(4)\n",
    "\n",
    "# 역전파\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(price)\n",
    "print(dapple_num, dapple, dorange_num, dorange, dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True]\n",
      " [ True False]]\n",
      "[-0.5 -2. ]\n"
     ]
    }
   ],
   "source": [
    "mask = (x <= 0)\n",
    "print(mask)\n",
    "print(x[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 순전파 때의 값이 0 이하면 역전파 때으이 값은 0이 돼야 합니다. 그래서 역전파 때는 순전파 때 만들어 둔 mask를 써서 mask의 원소가\n",
    "## True인 곳에는 상류에서 전파된 dout을 0으로 설정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5.2 Sigmoid 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.6 Affine/Softmax 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6.1 Affine 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.42476861 0.86920097 0.3489563 ]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(2) # 입력\n",
    "W = np.random.rand(2,3) # 가중치\n",
    "B = np.random.rand(3) # 편향\n",
    "\n",
    "X.shape # (2,)\n",
    "W.shape # (2, 3)\n",
    "B.shape # (3,)\n",
    "\n",
    "Y = np.dot(X, W) + B\n",
    "\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [11, 12, 13]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dot_W = np.array([[0,0,0],[10,10,10]])\n",
    "B = np.array([1,2,3])\n",
    "X_dot_W + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dY = np.array([[1,2,3],[4,5,6]])\n",
    "dY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dB = np.sum(dY, axis=0)\n",
    "dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6.3 Softmax-with-Loss 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실\n",
    "        self.y = None # softmax의 출력\n",
    "        self.t = None # 정답 렝비ㅡㄹ(원-핫 벡터)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_siize\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7.2 오차역전파법을 적용한 신경망 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_sizse)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(Self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layers in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    # x: 입력 데이터, t: 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim !=1:\n",
    "            t = np.argmax(t, axis =1)\n",
    "            \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    # x: 입력 데이터, t: 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        return grads\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        # 순전파\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        # 역전파\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Affine1'].dW\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['W2'] = self.layers['Affine2'].dW\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7.3 오차역전파법으로 구한 기울기 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:4.708171316987104e-13\n",
      "b1:1.3618995487558669e-12\n",
      "W2:1.5591975044415564e-11\n",
      "b2:1.1990408943507446e-10\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "# 각 가중치의 차이의 절댓값을 구한 후, 그 절댓값들의 평균을 낸다.\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "    print(key + ':' + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 학습 관련 기술들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.2 확률적 경사 하강법(SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의사코드(작동x)\n",
    "network = TwoLayerNet(...)\n",
    "optimizer = SGD()\n",
    "\n",
    "for i in range(10000):\n",
    "    ...\n",
    "    x_batch, t_batch = get_mini_batch(...) # 미니배치\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    params = network.params\n",
    "    optimizer.update(params, grads)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.4 모멘텀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": 모멘텀은 '운동량'을 뜻하는 단어로, 물리와 관계가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key,val in params.items():\n",
    "                self.v[key] = np.zeros_like(val) # np.zeros_like()는 0으로 만들어준다.\n",
    "                \n",
    "            for key in params.keys():\n",
    "                self.v[key] = self.momentum*self.v[key] - self.lr*grads[key]\n",
    "                params[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.5 AdaGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": 학습률 감소(learning rate decay)가 있다. 이는 학습을 진행하면서 학습률을 점차 줄여가는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "        \n",
    "        for key in params.keys():\n",
    "            self.h[key] += grads[key] * grads[key]\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.6 Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": 모멘텀과 AdaGrad를 융합한 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 가중치의 초깃값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2 은닉층의 활성화값 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "x = np.random.randn(1000, 100) # 1000개의 데이터\n",
    "node_num = 100 # 각 은닉층의 노드(뉴런) 수\n",
    "hidden_layer_size = 5 # 은닉층이 5개\n",
    "activations = {} # 이곳에 활성화 결과(활성화값)를 저장\n",
    "\n",
    "for i in range(hidden_layer_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "        \n",
    "    w = np.random.randn(node_num, node_num) * 1\n",
    "    a = np.dot(x, w)\n",
    "    z = sigmoid(a)\n",
    "    activations[i] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 히스토그램 그리기\n",
    "# 이번에는 표준편차가 1인 정규분포를 이용했는데, 이 분포된 정도(표준편차)를 바꿔가며\n",
    "# 활성화값들의 분포가 어떻게 변화하는지 관찰하는 것이 이 실험의 목적\n",
    "for i, a in activations.items():\n",
    "    plt.subplot(1, len(activations), i+1)\n",
    "    plt.title(str(i+1) + \"-layer\")\n",
    "    plt.hist(a.flatten(), 30, range=(0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터가 0과 1에 치우쳐 분포하게 되면 역전파의 기울기 값이 점점 작아지다가 사라짐\n",
    "# 이것이 기울기 소실(gradient vanishing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번에는 가중치의 표준편차를 0.01로 바꿔 같은 실험을 반복\n",
    "for i in range(hidden_layer_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "        \n",
    "    w = np.random.randn(node_num, node_num) * 0.01\n",
    "    a = np.dot(x, w)\n",
    "    z = sigmoid(a)\n",
    "    activations[i] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, a in activations.items():\n",
    "    plt.subplot(1, len(activations), i+1)\n",
    "    plt.title(str(i+1) + \"-layer\")\n",
    "    plt.hist(a.flatten(), 30, range=(0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0과 1로 치우치진 않았으나, 다수의 뉴런이 거의 같은 값을 출력하고 있으니\n",
    "# 뉴런을 여러 개 둔 의미가 없어진다는 뜻\n",
    "# 표현력을 제한한다는 관점에서 문제가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavier 초깃값\n",
    "node_num = 100 # 앞 층의 노드 수\n",
    "w = np.random.randn(node_num, node_num) / np.sqrt(node_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(hidden_layer_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "        \n",
    "    w = np.random.randn(node_num, node_num) / np.sqrt(node_num)    \n",
    "    a = np.dot(x, w)\n",
    "    z = sigmoid(a)\n",
    "    activations[i] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, a in activations.items():\n",
    "    plt.subplot(1, len(activations), i+1)\n",
    "    plt.title(str(i+1) + \"-layer\")\n",
    "    plt.hist(a.flatten(), 30, range=(0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 배치 정규화(Batch Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.1 배치 정규화 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 배치 정규화가 주목받는 이유 3가지\n",
    "1. 학습을 빨리 진행할 수 있다(학습 속도 개선).\n",
    "2. 초깃값에 크게 의존하지 않는다.(골치 아픈 초깃값 선택 장애여 안녕!).\n",
    "3. 오버피팅을 억제한다.(드롭아웃 등의 필요성 감소)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.2 배치 정규화의 효과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4 바른 학습을 위해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.1 오버피팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiLayerNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-77780ebec735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiLayerNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 학습률이 0.01인 SGD로 매개변수 갱신\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train size : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MultiLayerNet' is not defined"
     ]
    }
   ],
   "source": [
    "network = MultiLayerNet(input_size=784, hidden_size_list=[100,100,100,100,100,100], output_size=10)\n",
    "optimizer = SGD(lr=0.01) # 학습률이 0.01인 SGD로 매개변수 갱신\n",
    "max_epochs = 201\n",
    "train_size = x_train.shape[0]\n",
    "print(\"train size : \" + str(train_size))\n",
    "batch_size = 100\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "epoch_cnt = 0\n",
    "\n",
    "for i in range(1000000000):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    optimizer.update(network.params, grads)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        \n",
    "        epoch_cnt += 1\n",
    "        if epoch_cnt >= max_epochs:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.2 가중치 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.3 드롭아웃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_ratio=0.5):\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg:\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1.0 - self.dropout_ratio)\n",
    "        \n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": 기계학습에서는 앙상블 학습을 애용합니다. 앙상블 학습은 개별적으로 학습시킨 여러 모델의 출력을 평균 내어 추론하는 방식입니다.  \n",
    ": 앙상블 학습은 드롭아웃과 밀접합니다. 드롭아웃이 학습 때 뉴런을 무작위로 삭제하는 행위를 매번 다른 모델을 학습시키는 것으로 해석할 수 있기 때문이죠. 그리고 추론 때는 뉴런의 출력에 삭제한 비율을 곱함으로써 앙상블 학습에서 여러 모델의 평균을 내는 것과 같은 효과를 얻는 것이죠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5 적절한 하이퍼파라미터 값 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5.1 검증 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 훈련데이터(Training Set) : 매개변수 학습\n",
    "2. 검증데이터(Validation Set) : 하이퍼파라미터 성능 평가\n",
    "3. 시험데이터(Test Set) : 신경망의 범용 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import util\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist()\n",
    "\n",
    "# 훈련 데이터를 뒤섞는다.\n",
    "x_train, t_train = util.shuffle_dataset(x_train, t_train)\n",
    "\n",
    "# 20%를 검증 데이터로 분할\n",
    "validation_rate = 0.20\n",
    "validation_num = int(x_train.shape[0] * validation_rate)\n",
    "\n",
    "x_val = x_train[:validation_num]\n",
    "t_val = t_train[:validation_num]\n",
    "x_train = x_train[validation_num:]\n",
    "t_train = t_train[validation_num:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5.2 하이퍼파라미터 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": 최적화를 하기 위해서는 굉장히 오랜 시간이 걸린다. 과학이라기보다는 '지혜'와 '직관'에 의존한다는 느낌이 든다. 더 세련된 기법을 원한다면 베이즈 최적화(Bayesian optimization)를 활용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
